Abstract. An index is a very good tool for ﬁnding the necessary information from a set of documents. So far, the extant index tools in both the
printed and digital newspaper versions are not suﬃcient to help users ﬁnd
information. Users must browse the entire newspaper to fulﬁll their needs
or discover later on, after spending a considerable amount of energy, that
the information they had been seeking is not available. We propose here
to use state-of-the-art strategies for extracting named entities speciﬁcally
for person names and, with an index of names, provide the user with an
important tool to ﬁnd names within newspaper pages. The state-of-theart system considered used the Golden Collection of the First and Second HAREM, a reference for Named Entity Recognition systems in Portuguese, as training and test sets respectively. Furthermore, we created
a new training dataset from the actual newspaper’s articles. In this case,
we processed 100 articles of the newspaper and managed to correctly
ﬁnd 87.0% of the extant names and their respective partial citations.

1

Introduction

The identiﬁcation of a person’s name in free written text is a tough task within
the Named Entity Recognition (NER) research area. It has been more than
twenty years since the Message Understanding Conference – 6 (MUC-6) added
the task of identiﬁcation and classiﬁcation of the Named Entities (Named Entity
Task – NE) [8], due to its importance in promoting the development in this area.
This task can be unfolded into three other subtasks: entity names, temporal
expressions, and number expressions. We are interested in the ﬁrst group, which
we tagged with <EM ID="xxx" CATEG="PESSOA"> when found in the text, where
ID is a unique identiﬁer for this occurrence.
This problem is relevant in many real-life areas. For instance, according to [2], NER is a fundamental step of preprocessing tasks in Information
Retrieval (IR) for several other applications (e.g., relation and event extraction).
Another example is the work developed in [12], where the objective is to extract
gene, protein and other biomedical entities mentions using a machine learning
algorithm.
c Springer Nature Switzerland AG 2018
A. Villavicencio et al. (Eds.): PROPOR 2018, LNAI 11122, pp. 147–155, 2018.
https://doi.org/10.1007/978-3-319-99722-3_15

148

J. P. C. Pirovani et al.

The problem can get more complex depending on the domain of the texts
one aims to work on. This is the case in texts in social media, where there
is no strict pattern to refer to names, in particular people’s names. A similar
situation is the extraction of names from newswired texts. Names can appear
in many forms: (a) complete – where all parts are always presented, the ﬁrst,
middle name and surname, and all of them have initial capitalization; (b) partial
– where sometimes only the surname is used, or alternatively a combination of
the use of the ﬁrst name together with the surname; and (c) a reference – this is
the case when one decides to use a nickname instead of using the person’s real
name.
The main approaches used by systems that automatically identify names in
texts are: (a) linguistic methods based on manually built rules [6], (b) probabilistic methods based on machine learning strategies [4], and (c) hybrid methods that combine both methods [17]. In 2004, the linguistic approach was considered by [7] as the most frequent approach used for NER. The rules of this
approach allow one to build a very neat local grammar (LG) for the speciﬁc
problem at hand. In 2012, the most recent works in NER already used statistical machine learning methods such as Hidden Markov Models and Conditional
Random Fields [2].
In this paper, we adopted a hybrid approach proposed in [17] to ﬁnd person
oria –
names from pages of a local online newspaper called “A Tribuna”1 , in Vit´
Esp´ırito Santo, Brazil. In addition to presenting state-of-the-art results for Portuguese, the strategy combines advantages of the linguistic and machine learning
approaches. The names found were used to create a webpage of person names
index. This webpage allows the user to easily access all the newspaper articles
where their names appear. This webpage will be also used to improve the proposed strategy by oﬀering the user the opportunity of pointing us out a name
we have missed out from any newspaper’s page, when this happens.
This paper is organized as follows. In Sect. 2, we present a brief revision of
the main related works to what we are pursuing here. Next, we describe our work
methodology, the metrics we used and give an idea of the application we built as
a result of our work. Next, in Sect. 4, we describe the process of experimentation
we used to achieve the results we discuss in this work as well as the new training
dataset we introduced as a possible benchmark for future works. To sum up, in
Sect. 5, our conclusions and future work are presented.

2

The Literature Review

In [5], some linguistic properties of proper names considering European Portuguese are presented. The goal is to assist the automatic processing of texts in
this language. Some properties of the formal variations (concordance of number
and gender) are also presented, as in this language some names accept the plural
form (e.g., Antˆ
onio is smart, the singular, and – The Antˆ
onios are smart, the
plural form). In addition, some combinatorial restrictions are also presented as
1

https://tribunaonline.com.br/.

Indexing Names of Persons in a Large Dataset of a Newspaper

149

the existence of prepositions between names (e.g., Maria de Lurdes) and the
existence of a few compound nouns connected by a hyphen (e.g., Jose-Maria).
This information is represented by the ﬁnite state automata and, furthermore,
they presented a proposal to formalize a way to describe people’s names in
dictionaries.
One related work regarding identifying names in newspaper articles written
in French is described in [7]. In this work, the author carried out a linguistic
text analysis to build a series of cascaded ﬁnite state transducers in which each
one is capable of transforming input texts into other suitable texts for some
information extraction. This analysis sought to identify the context prior to and
after people’s names. The system, called CasSys, was implemented upon the
Intex2 tool. Two are the transducers used for extracting names in [7]. The ﬁrst
one uses a list of rules describing a local grammar and the second uses the names
identiﬁed by the ﬁrst transducer to search for the remaining names.
Local Grammars (LG) were created by [11] for use in an NER system in
the Serbian language. The system uses electronic dictionaries with a rich set of
semantic tags and LGs that describe the context of NEs to recognize: person
names, geopolitical names, temporal and numerical expressions. They produced
special LGs for recognizing a person’s position in society. The system was evaluated in short agency news, and Recall and Precision metrics were manually
computed. The results suggest that the system prioritizes Precision.
Another approach presented by [6] is designed to identify person names in
Portuguese texts using an LG created based on a linguistic study of these texts.
Initially, the authors built a LG for the book titled Senhora by Jos´e de Alencar, and then later applied this same grammar to articles to the A Tribuna, a
local newspaper in Esp´ırito Santo. The goal was to observe the appropriation of
an LG built from one context to another. While this is possible, some adaptations were necessary. The performance achieved for the newspaper articles was
lower because the LG was not built speciﬁcally for that corpus owing to its particularities in the ways names were presented, conﬁrming that the automatic
identiﬁcation of names is corpus dependent.
On the other hand, some machine learning approaches (e.g., [4,14,16]) have
used machine learning techniques such as Hidden Markov Models (HMM),
Transformation-Based Learning (TBL), Support Vector Machines (SVM), Conditional Random Fields (CRF), Naive Bayes and Decision Table for NER over
Portuguese texts.
Despite these two basic approaches, some hybrid approaches are found in
the literature. For instance, the CRF for Portuguese NER was used by [18] to
identify and classify the 10 categories of HAREM3 NEs. The IO [10] notation
with the HAREM-deﬁned categories, the corpus annotated with part-of-speech
tags (POS-tagging) and a feature vector are used as input for the training phase.
In the testing phase, the HAREM-deﬁned categories are removed. The HAREM
corpora was used for training and testing.
2
3

http://www.nyu.edu/pages/linguistics/intex/.
http://www.linguateca.pt/HAREM/.

150

J. P. C. Pirovani et al.

In this paper, we show a very useful application of NER. This application is in
a form of an index of person names, identiﬁed by a hybrid approach considering
the speciﬁcity of Portuguese language. This is our ﬁrst step toward a more general
research goal, which consists of the automatic knowledge base extraction from
free texts.

3

The Methodology

In our case study, a name can appear many times within the newspaper article
as the journalist decides to cite a person more than once. Our tool will tag all
the occurrences and build a webpage with all of them highlighted so that the
user can easily locate the name. Figure 1 shows the step-by-step process to mark
the names on the newspaper page.

Fig. 1. The processing ﬂow for extracting names from the online newspaper

The ﬁrst step is done by daily downloading PDFs of the newspaper articles
from the A Tribuna newspaper public site. These ﬁles are scanned by the Tesseract API [1]. Tesseract is an open source tool that performs Optical Character
Recognition (OCR), which allows us to obtain plain ASCII searchable-text ﬁles
from the PDFs. After this, these texts are preprocessed. This is the process in
charge of tasks such as removing empty lines and accounting for the hyphens at
the ends of lines, which are common in newspaper articles due to the column
layout style [15]. All these steps were carried out by a set of shell-script codes,
which we are planning to make fully automatic soon.
The next step is the Named Entity Recognition (NER). To the best of our
knowledge, the state-of-the-art solution for the extraction of names in Portuguese
language is the work presented in [17]. This is a hybrid approach where Conditional Random Fields (CRF) is used in combination with handmade Local
Grammars (LGs) to capture the logic behind the process of naming recognition.
Their results signiﬁcantly surpass previous results [3,20]. In addition, [19] also
successfully used this strategy at automatic question generation from entities
named.
CRF is a probabilistic method for structured prediction proposed by [13],
which has been successfully used in several Natural Language Processing (NLP)
tasks and LGs [9] are one means of representing rules of the linguistic approach
in which NEs can appear. The classiﬁcation obtained from LG is sent as an

Indexing Names of Persons in a Large Dataset of a Newspaper

151

additional feature for the learning process of the CRF prediction model. That
is, the classiﬁcation obtained from LGs can be seen as a suggestion for the CRF.
The CRF model was trained using the HAREM corpus. HAREM is a joint
assessment for Portuguese and the annotated corpora used in the First and
Second HAREM, known as the Golden Collections (GC), have served as a golden
standard reference for NER systems in Portuguese. The HAREM standard was
used for the NE marking. Thus, after the NER, each text sentence has the NE
annotated between the <EM> and </EM> tags containing the NE category
PESSOA (PERSON) as in the following example:
According to the author, <EM ID=‘‘H2-bbb-3’’ CATEG=‘‘PERSON’’>
Jos´
e Mourinho </EM> is different because of a new paradigm of
thought.
(Segundo o autor, <EM ID=‘‘H2-bbb-3’’ CATEG=‘‘PESSOA’’> Jos´
e
Mourinho </EM> e
´ diferente por partir de um novo paradigma de
pensamento.)
Our system can be seen on the website4 . Figure 2 is an example of how the
results are shown to the user. First, the user looks for the target name on the
project webpage. On the right side of each name there are some links (pages of

Fig. 2. A screenshot of a section of the newspaper page
4

http://vitoriavirtual.com.br/indexingNewsPapers/.

152

J. P. C. Pirovani et al.

the newspaper where the searched name appears) to take the user to another
webpage where they can see the name highlighted, as presented in Fig. 2. In this
ﬁgure, we searched for the name Marcos. Our search was nearly 100% accurate.
We missed the name MARCOS on the bottom left side of the ﬁrst picture on
the page, as it appears in all capital letters.

4

The Experiments

We conducted some initial experiments to evaluate the performance of the NER
approach used in the articles from the A Tribuna newspaper since the experiments performed in [17] used the HAREM corpus as a test dataset and considered
all the categories of the HAREM.
We prepared a set of 100 news articles to annotate from the actual newspaper
we are interested in – the A Tribuna corpus. The articles were randomly selected
among the articles of politics and economics and the resulting text contains
101733 words. We asked a number of undergraduate students to annotate all
the person’s name in all the articles by using Etiquet(H)arem5 . The students
found 2714 person’s name in the 100 documents. The metrics of Precision (P),
Recall (R) and F-Measure (F) were computed using the evaluation scripts from
the Second HAREM.
In the ﬁrst experiment, the 100 new annotated articles were used as a test
dataset. We applied the LG built by the authors in [17] solely, and we also applied
the CRF+LG proposed by [17] for the NER in the A Tribuna corpus. CRF+LG
was applied considering the GC of the First HAREM as training set and considering all GCs of the HAREM (First HAREM, Mini HAREM and Second
HAREM) as training set. We show these results (Experiment 1) in Table 1.
Table 1. Evaluation of LG and CRF+LG
Experiment 1

P (%) R (%) F(%)

LG

83.51

25.52

39.10

CRF+LG (Training: GC of the First HAREM) 76.15

29.19

42.20

CRF+LG (Training: GCs HAREM)

40.47

53.71

79.85

Experiment 2
CRF+LG (Training: original ATribuna)

82.70

47.16

60.07

CRF+LG (Training: improved ATribuna)

87.34

48.21

62.13

The Recall value obtained by LG individually was lower because LG captures
only some general heuristics for NER and because this LG was not built specifically for the A Tribuna corpus that has its own particularities concerning the
way the names are written. As expected, the gain obtained (11.5% in F-measure)
5

http://www.linguateca.pt/poloCoimbra/recursos/etiquetharem.zip.

Indexing Names of Persons in a Large Dataset of a Newspaper

153

by CRF+LG using all GCs of the HAREM as training was higher in comparison
to the training using only the GC of the First HAREM because the training set
is much larger and allows the number of entities identiﬁed (Recall) to increase
considerably.
After the ﬁrst experiment, we also considered using articles of the A Tribuna
corpus for training and testing because we know that NER depends on the
corpus. Then, in the second experiment, we deﬁned training and test subsets for
the A Tribuna corpus using the holdout sampling method. We used the most
common split, 2/3 of the corpus was used for training and 1/3 for testing. The
results can be seen in Table 1 (Training: original ATribuna).
Note that the results obtained outperform the best results of the ﬁrst experiment in almost 3% for the Precision metric and more than 6% for the Recall
and F-measure metrics, representing considerable gain.
By analyzing the false positives and false negatives, we observed that some
persons’ names were correctly annotated by CRF+LG but were considered
wrong when computing the Precision metric because they were not annotated
by the students. That is, the students missed some names during the annotation. We thus annotated these names after obtaining a new A Tribuna annotated
corpus and performed this experiment again. The results presented in Table 1
(Training: improved ATribuna) shows that we achieved a gain of approximately
5% in the Precision metric.
Despite preliminary results, we consider them to be promising. We believe
that with a larger annotated corpus, the Recall value would be further increased.
In addition, a further improvement of the LG to recognize additional names in
the A Tribuna corpus can enable us to achieve even better results. We also
observed that the automatic tool, CRF+LG, can be used for debugging in the
process of building a good training dataset.

5

Conclusions

We showed in this work a combined approach for indexing peoples’ names within
newspaper pages. For this aim, we trained our algorithms with the HAREM very
well-known dataset collection for benchmarks and, in addition, we created a new
collection for training and test from actual articles extracted from the newspaper.
We tested our approach over 100 newspaper pages. The names we searched
for are now posted on our web page, where any user can browse for a name and
then go straight to the point where the name is cited within the newspaper page.
The quality of the results we produced is promising, as on average, we yielded
a 87.34% of Precision and 48.21% of Recall which will be improved as we train
CRF+LG from a larger annotated corpus. The index of names gives us a powerful
tool to help the experts ﬁnd newspapers articles which mention given target
names.
Our plans for the future of this work are as follows: ﬁrst, we want to better
improve our capacity of quickly building tailored LGs for the identiﬁcation of
person names. For the current work, we already used the concordance comparison

154

J. P. C. Pirovani et al.

tool built in the Unitex as a computational aid in the manual composition of
LGs. We claim that this is a promising tool to be mastered and combined within
our automatic framework. Second, we want to improve the process of building
and correcting the training data from a given newspaper corpus by being able
to incrementally learn from the comparison of the human versus the automatic
annotation approach.
Acknowledgments. We would like to thank the reviewers for their insightful comments on the paper, as these comments led us to an improvement of the work.